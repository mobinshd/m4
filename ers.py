# -*- coding: utf-8 -*-
"""ERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J8CWOphzuv42DHbDK9Z-jP17Jx-GO9Lh
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import gzip
import matplotlib.pyplot as plt
import numpy as np
import pymc3 as pm
from sklearn.metrics import mean_squared_error
import logging
import time
import scipy as sp
import theano
import gc

#@title


def parse(path):
  g = gzip.open(path, 'rb')
  for l in g:
    yield eval(l)

def getDF(path):
  i = 0
  df = {}
  for d in parse(path):
    df[i] = d
    i += 1
  return pd.DataFrame.from_dict(df, orient='index')

df = getDF('/content/drive/MyDrive/amazonDS/reviews_Grocery_and_Gourmet_Food_5.json.gz')

df.rename(columns={"reviewerID": "userID", "asin": "itemID","overall":"rating"},inplace=True)
df

df.groupby('rating').size().plot(kind="bar");

df['rating'].describe()

item_means=df.groupby('itemID').rating.mean()
item_means[:50].plot(kind="bar", grid=False, figsize=(16, 6), title="Mean ratings for 50 items");

fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(32,8), sharey=True)
item_means.nlargest(50).plot(kind="bar", ax=ax1, title="Top 50 items in data set")
item_means.nsmallest(50).plot(kind="bar", ax=ax2, title="Bottom 50 items in data set");

user_means = df.groupby("userID").rating.mean().sort_values()
_, ax = plt.subplots(figsize=(20, 6))
ax.plot(np.arange(len(user_means)), user_means.values, "k-")

ax.fill_between(np.arange(len(user_means)), user_means.values, alpha=0.3)
ax.set_xticklabels("")
# 1000 labels is nonsensical
ax.set_ylabel("Rating")
ax.set_xlabel(f"{len(user_means)} average ratings per user")
ax.set_ylim(0, 5)
ax.set_xlim(0, len(user_means));

def split_title(title):
    """Change "BaselineMethod" to "Baseline Method"."""
    words = []
    tmp = [title[0]]
    for c in title[1:]:
        if c.isupper():
            words.append("".join(tmp))
            tmp = [c]
        else:
            tmp.append(c)
    words.append("".join(tmp))
    return " ".join(words)


class Baseline:
    """Calculate baseline predictions."""

    def __init__(self, train_data):
        """Simple heuristic-based transductive learning to fill in missing
        values in data matrix."""
        self.predict(train_data.copy())

    def predict(self, train_data):
        raise NotImplementedError("baseline prediction not implemented for base class")

    def mse(self, test_data):
        """Calculate mean squared error for predictions on test data."""
        return mse(test_data, self.predicted)

    def __str__(self):
        return split_title(self.__class__.__name__)


# Implement the 3 baselines.


class UniformRandomBaseline(Baseline):
    """Fill missing values with uniform random values."""

    def predict(self, train_data):
        nan_mask = np.isnan(train_data)
        masked_train = np.ma.masked_array(train_data, nan_mask)
        pmin, pmax = masked_train.min(), masked_train.max()
        N = nan_mask.sum()
        train_data[nan_mask] = np.random.uniform(pmin, pmax, N)
        self.predicted = train_data


class GlobalMeanBaseline(Baseline):
    """Fill in missing values using the global mean."""

    def predict(self, train_data):
        nan_mask = np.isnan(train_data)
        train_data[nan_mask] = train_data[~nan_mask].mean()
        self.predicted = train_data


class MeanOfMeansBaseline(Baseline):
    """Fill in missing values using mean of user/item/global means."""

    def predict(self, train_data):
        nan_mask = np.isnan(train_data)
        masked_train = np.ma.masked_array(train_data, nan_mask)
        global_mean = masked_train.mean()
        user_means = masked_train.mean(axis=1)
        item_means = masked_train.mean(axis=0)
        self.predicted = train_data.copy()
        n, m = train_data.shape
        for i in range(n):
            for j in range(m):
                if np.ma.isMA(item_means[j]):
                    self.predicted[i, j] = np.mean((global_mean, user_means[i]))
                else:
                    self.predicted[i, j] = np.mean((global_mean, user_means[i], item_means[j]))

baseline_methods = {}
baseline_methods["ur"] = UniformRandomBaseline
baseline_methods["gm"] = GlobalMeanBaseline
baseline_methods["mom"] = MeanOfMeansBaseline

num_users = df.userID.unique().shape[0]
num_items = df.itemID.unique().shape[0]
sparsity = 1 - len(df) / (num_users * num_items)
print(f"Users: {num_users}\nMovies: {num_items}\nSparsity: {sparsity}")

dense_data = df.pivot(index="userID", columns="itemID", values="rating")

dense_data.shape

dense_data.loc['A1VEELTKS8NLZB','616719923X']

theano.config.compute_test_value = "ignore"

# Set up logging.
logger = logging.getLogger()
logger.setLevel(logging.INFO)

ee=np.eye(3)
ee=ee*0.2
ee

rr=np.random.randn(20, 5)*0.01
rr

class PMF:

    def __init__(self, train, dim, alpha=2, std=0.01, bounds=(1, 5)):
        """Build the Probabilistic Matrix Factorization model using pymc3.

        :param np.ndarray train: The training data to use for learning the model.
        :param int dim: Dimensionality of the model; number of latent factors.
        :param int alpha: Fixed precision for the likelihood function.
        :param float std: Amount of noise to use for model initialization.
        :param (tuple of int) bounds: (lower, upper) bound of ratings.
            These bounds will simply be used to cap the estimates produced for R.

        """
        self.dim = dim
        self.alpha = alpha
        self.std = np.sqrt(1.0 / alpha)
        self.bounds = bounds
        self.data = train.copy()
        n, m = self.data.shape

        # Perform mean value imputation
        nan_mask = np.isnan(self.data)
        self.data[nan_mask] = self.data[~nan_mask].mean()

        # Low precision reflects uncertainty; prevents overfitting.
        # Set to the mean variance across users and items.
        self.alpha_u = 1 / self.data.var(axis=1).mean()
        self.alpha_v = 1 / self.data.var(axis=0).mean()
        
        # Specify the model.
        logging.info("building the PMF model")
        with pm.Model() as pmf:
            U = pm.MvNormal(
                "U",
                mu=0,
                tau=self.alpha_u * np.eye(dim),
                shape=(n, dim),
                testval=np.random.randn(n, dim) * std,
            )
            print(U)
            V = pm.MvNormal(
                "V",
                mu=0,
                tau=self.alpha_v * np.eye(dim),
                shape=(m, dim),
                testval=np.random.randn(m, dim) * std,
            )
            R = pm.Normal(
                "R", mu=(U @ V.T)[~nan_mask], tau=self.alpha, observed=self.data[~nan_mask]
            )

        logging.info("done building the PMF model")
        self.model = pmf

    def __str__(self):
        return self.name

def _find_map(self):
  """Find mode of posterior using L-BFGS-B optimization."""
  tstart = time.time()
  with self.model:
    logging.info("finding PMF MAP using L-BFGS-B optimization...")
    self._map = pm.find_MAP(method="L-BFGS-B")

  elapsed = int(time.time() - tstart)
  logging.info("found PMF MAP in %d seconds" % elapsed)
  return self._map


def _map(self):
    try:
        return self._map
    except:
        return self.find_map()

# Update our class with the new MAP infrastructure.
PMF.find_map = _find_map
PMF.map = property(_map)

# Draw MCMC samples.
def _draw_samples(self, **kwargs):
    kwargs.setdefault("chains", 1)
    with self.model:
        self.trace = pm.sample(**kwargs)

# Update our class with the sampling infrastructure.
PMF.draw_samples = _draw_samples

def _predict(self, U, V):
    """Estimate R from the given values of U and V."""
    R = np.dot(U, V.T)
    n, m = R.shape
    sample_R = np.random.normal(R, self.std)
    # bound ratings
    low, high = self.bounds
    sample_R[sample_R < low] = low
    sample_R[sample_R > high] = high
    return sample_R

PMF.predict = _predict

def mse(test_data, predicted):
    """Calculate root mean squared error.
    Ignoring missing values in the test data.
    """
    I = ~np.isnan(test_data)  # indicator for missing values
    N = I.sum()  # number of non-missing values
    sqerror = abs(test_data - predicted) ** 2  # squared error array
    mse = sqerror[I].sum() / N  # mean squared error
    return mse  # MSE

def split_train_test(data, percent_test=0.1):
    """Split the data into train/test sets.
    :param int percent_test: Percentage of data to use for testing. Default 10.
    """
    n, m = data.shape  # # users, # movies
    N = n * m  # # cells in matrix
 
    # Prepare train/test ndarrays.
    train = data.to_numpy()
   
    test = np.ones(data.shape) * np.nan
  
  
    # Draw random sample of training data to use for testing.
    tosample = np.where(~np.isnan(train))  # ignore nan values in data
    idx_pairs = list(zip(tosample[0], tosample[1]))  # tuples of row/col index pairs
    print(idx_pairs)
    test_size = int(len(idx_pairs) * percent_test)  # use 10% of data as test set
    train_size = len(idx_pairs) - test_size  # and remainder for training

    indices = np.arange(len(idx_pairs))  # indices of index pairs
    sample = np.random.choice(indices, replace=False, size=test_size)
 
    # Transfer random sample from train set to test set.
    for idx in sample:
        idx_pair = idx_pairs[idx]
        test[idx_pair] = train[idx_pair]  # transfer to test set
        train[idx_pair] = np.nan  # remove from train set

    # Verify everything worked properly
    assert train_size == N - np.isnan(train).sum()
    assert test_size == N - np.isnan(test).sum()

    # Return train set and test set
    return train, test

gc.collect()
gc.collect(0)
gc.collect(1)
gc.collect(2)

train, test = split_train_test(dense_data)

baselines = {}
for name in baseline_methods:
    Method = baseline_methods[name]
    method = Method(train)
    baselines[name] = method.mse(test)
    print("{} MSE:\t{:.5f}".format(method, baselines[name]))

pmf = PMF(train,dim=10, alpha=2, std=0.05)

gc.collect()
gc.collect(0)
gc.collect(1)
gc.collect(2)

pmf.find_map()

def eval_map(pmf_model, train, test):
    U = pmf_model.map["U"]
    V = pmf_model.map["V"]

    # Make predictions and calculate RMSE on train & test sets.
    predictions = pmf_model.predict(U, V)
    train_mse = mse(train, predictions)
    test_mse = mse(test, predictions)
    overfit = test_mse - train_mse

    # Print report.
    print("PMF MAP training MSE: %.5f" % train_mse)
    print("PMF MAP testing MSE:  %.5f" % test_mse)
    print("Train/test difference: %.5f" % overfit)

    return test_mse

PMF.eval_map = eval_map

pmf_map_mse = pmf.eval_map(train, test)
pmf_improvement = baselines["mom"] - pmf_map_mse
print("PMF MAP Improvement:   %.5f" % pmf_improvement)

gc.collect()
gc.collect(0)
gc.collect(1)
gc.collect(2)

# Draw MCMC samples.
pmf.draw_samples(
    draws=20,
    tune=20,
)

def _norms(pmf_model, monitor=("U", "V"), ord="fro"):
    """Return norms of latent variables at each step in the
    sample trace. These can be used to monitor convergence
    of the sampler.
    """
    monitor = ("U", "V")
    norms = {var: [] for var in monitor}
    for sample in pmf_model.trace:
        for var in monitor:
            norms[var].append(np.linalg.norm(sample[var], ord))
    return norms


def _traceplot(pmf_model):
    """Plot Frobenius norms of U and V as a function of sample #."""
    trace_norms = pmf_model.norms()
    u_series = pd.Series(trace_norms["U"])
    v_series = pd.Series(trace_norms["V"])
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))
    u_series.plot(kind="line", ax=ax1, grid=False, title=r"$\|U\|_{Fro}^2$ at Each Sample")
    v_series.plot(kind="line", ax=ax2, grid=False, title=r"$\|V\|_{Fro}^2$ at Each Sample")
    ax1.set_xlabel("Sample Number")
    ax2.set_xlabel("Sample Number")

PMF.norms = _norms
PMF.traceplot = _traceplot

pmf.traceplot()

gc.collect()
gc.collect(0)
gc.collect(1)
gc.collect(2)

def _running_mse(pmf_model, test_data, train_data, burn_in=0, plot=True):
    """Calculate MSE for each step of the trace to monitor convergence."""
    burn_in = burn_in if len(pmf_model.trace) >= burn_in else 0
    results = {"per-step-train": [], "running-train": [], "per-step-test": [], "running-test": []}
    R = np.zeros(test_data.shape)
    running_R=0
    for cnt, sample in enumerate(pmf_model.trace[burn_in:]):
        sample_R = pmf_model.predict(sample["U"], sample["V"])
        R += sample_R
        running_R = R / (cnt + 1)
        results["per-step-train"].append(mse(train_data, sample_R))
        results["running-train"].append(mse(train_data, running_R))
        results["per-step-test"].append(mse(test_data, sample_R))
        results["running-test"].append(mse(test_data, running_R))

    results = pd.DataFrame(results)

    if plot:
        results.plot(
            kind="line",
            grid=False,
            figsize=(15, 7),
            title="Per-step and Running MSE From Posterior Predictive",
        )

    # Return the final predictions, and the RMSE calculations
    return running_R, results

PMF.running_mse = _running_mse

predicted, results = pmf.running_mse(test, train)

# And our final RMSE?
final_test_mse = results["running-test"].values[-1]
final_train_mse = results["running-train"].values[-1]
print("Posterior predictive train MSE: %.5f" % final_train_mse)
print("Posterior predictive test MSE:  %.5f" % final_test_mse)
print("Train/test difference:           %.5f" % (final_test_mse - final_train_mse))
print("Improvement from MAP:            %.5f" % (pmf_map_mse - final_test_mse))
print("Improvement from Mean of Means:  %.5f" % (baselines["mom"] - final_test_mse))

size = 100  # RMSE doesn't really change after 100th sample anyway.
all_results = pd.DataFrame(
    {
        "uniform random": np.repeat(baselines["ur"], size),
        "global means": np.repeat(baselines["gm"], size),
        "mean of means": np.repeat(baselines["mom"], size),
        "PMF MAP": np.repeat(pmf_map_mse, size),
        "PMF MCMC": results["running-test"][:size],
    }
)
fig, ax = plt.subplots(figsize=(10, 5))
all_results.plot(kind="line", grid=False, ax=ax, title="MSE for all methods")
ax.set_xlabel("Number of Samples")
ax.set_ylabel("MSE");